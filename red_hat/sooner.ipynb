{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\compat\\pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import h2o\n",
    "import xgboost\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pylab as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import *\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "\n",
    "from h2o.estimators.random_forest import H2ORandomForestEstimator\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.max_rows', 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def str_to_num(df, train=True, activity_id = True):\n",
    "    '''\n",
    "    ppl_id : del string and change dtype to num\n",
    "    activity id : del number and str(act)\n",
    "    type : del string and change dtype to num\n",
    "    bool : 0, 1\n",
    "    inplace : True\n",
    "    \n",
    "    parameta\n",
    "    --------\n",
    "    df : DataFrame \n",
    "    train : bool\n",
    "        train :True, test : False\n",
    "    --------\n",
    "    '''\n",
    "    col_list = list(df)\n",
    "    col_list.remove('date_x')\n",
    "    col_list.remove('date_y')\n",
    "    if train:\n",
    "        col_list.remove('outcome')\n",
    "        \n",
    "    for col in col_list[:col_list.index('char_9_y')+1]:\n",
    "        if col == 'activity_id':\n",
    "            if activity_id == True:\n",
    "                df.loc[:,col] = df.loc[:,col].apply(lambda x: x.split('_')[0])\n",
    "                df.replace('act', '', regex=True, inplace = True)\n",
    "        elif col == 'people_id':\n",
    "            df.loc[:,col] = df.loc[:,col].apply(lambda x: x.split('_')[1])\n",
    "        else :\n",
    "            df.loc[:,col][df.loc[:,col].isnull()==False] = df.loc[:,col][df.loc[:,col].isnull()==False].apply(lambda x: x.split(' ')[1])\n",
    "        df.loc[:, col] = pd.to_numeric(df.loc[:, col][df.loc[:,col].isnull()==False]).astype(int)\n",
    "            \n",
    "    for col in col_list[col_list.index('char_10_y'):col_list.index('char_38')+1]:\n",
    "        df.loc[:,col] = df.loc[:,col].replace({True:1, False:0})\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def date_modify(df):\n",
    "    '''\n",
    "    add week_x, week_y, and Past_days\n",
    "    inplace : True\n",
    "    \n",
    "    parameta\n",
    "    --------\n",
    "    df : DataFrame \n",
    "    --------\n",
    "    '''\n",
    "    df.insert(loc=list(df).index('date_x')+1 ,column='week_x', value=df['date_x'].dt.weekday)\n",
    "    df.insert(loc=list(df).index('date_y')+1 ,column='week_y', value=df['date_y'].dt.weekday)\n",
    "    df.insert(loc=list(df).index('week_x')+1 ,column='Past_days', value=(df.date_x - df.date_y).astype('timedelta64[D]'))\n",
    "    df['days']=(pd.to_numeric(df.date_x)//86400000000000) - (pd.to_numeric(df.date_x)//86400000000000).min()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_bool_sum(df):\n",
    "    '''\n",
    "    add colum 'bool_sum' : sum of char_10_y ~ char_37\n",
    "    inplace : False\n",
    "    \n",
    "    parameta\n",
    "    --------\n",
    "    df : DataFrame \n",
    "    --------\n",
    "    '''\n",
    "    temp = df.copy()\n",
    "    temp['bool_sum'] = temp.iloc[:,list(temp).index('char_10_y'):list(temp).index('char_37')].sum(axis=1)\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def num_to_cat(df, columns):\n",
    "    '''\n",
    "    change dtype(num to str)\n",
    "    inplace : False\n",
    "    \n",
    "    parameta\n",
    "    --------\n",
    "    df : DataFrame \n",
    "    columns : list\n",
    "    --------\n",
    "    '''\n",
    "    temp = df.copy()\n",
    "    temp.loc[:,columns] = pd.DataFrame(temp.loc[:,columns], dtype='str')\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def one_hot_encoder(df, columns):\n",
    "    '''\n",
    "    columns encoding(one-hot-encoding)\n",
    "    inplace : False\n",
    "    \n",
    "    parameta\n",
    "    --------\n",
    "    df : DataFrame \n",
    "    columns : list\n",
    "    --------\n",
    "    '''\n",
    "    temp = df.copy()\n",
    "    for col in columns:\n",
    "        for i in list(pd.get_dummies(temp[col]))[-1::-1]:    \n",
    "            temp.insert(loc=list(temp).index(col)+1 ,column=col+str(i), value=pd.get_dummies(temp.loc[:,col]).loc[:,i])\n",
    "        temp = temp.drop([col], axis=1)\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import pydot\n",
    "from IPython.core.display import Image \n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "# 강사님 함수\n",
    "def draw_decision_tree(model, feature_names):\n",
    "    dot_buf = io.StringIO() \n",
    "    export_graphviz(model, out_file=dot_buf, feature_names=feature_names)\n",
    "    graph = pydot.graph_from_dot_data(dot_buf.getvalue())[0] \n",
    "    image = graph.create_png()\n",
    "    return Image(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data load & 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('./data/act_train.csv', parse_dates=['date'])\n",
    "df_people = pd.read_csv('./data/people.csv', parse_dates=['date'])\n",
    "df_merge = pd.merge(df_train, df_people, on='people_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "str_to_num(df_merge, train=True)\n",
    "date_modify(df_merge)\n",
    "df_merge = add_bool_sum(df_merge)\n",
    "del df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('./data/act_test.csv', parse_dates=['date'])\n",
    "df_merge_test = pd.merge(df_test, df_people, how='inner', on='people_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# submissin 만들때 필요함\n",
    "df_test_act_id = df_merge_test.activity_id.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_to_num(df_merge_test, train=False)\n",
    "date_modify(df_merge_test)\n",
    "df_merge_test = add_bool_sum(df_merge_test)\n",
    "del df_test, df_people"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df_merge.to_csv(\"train_merge.csv\")\n",
    "# df_merge_test.to_csv(\"test_merge.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df_merge = pd.read_csv('./train_merge.csv', parse_dates=['date_x', 'date_y'])\n",
    "# df_merge_test = pd.read_csv('./test_merge.csv', parse_dates=['date_x', 'date_y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# group & date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_gd = df_merge.loc[:, ['group_1', 'days', 'outcome']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_gd_test = pd.DataFrame({'activity_id' : df_test_act_id, 'group_1' : df_merge_test.group_1, 'days' : df_merge_test['days'], 'outcome':np.nan})         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "gp_0 = []\n",
    "gp_1 = []\n",
    "gp_01= []\n",
    "for gp in df_gd.group_1.unique():\n",
    "    if len(df_gd[df_gd.group_1==gp].loc[:,'outcome'].unique()) == 1:\n",
    "        if df_gd[df_gd.group_1==gp].loc[:,'outcome'].iloc[0]:\n",
    "            gp_1.append(gp)\n",
    "        else:\n",
    "            gp_0.append(gp)\n",
    "    else :\n",
    "        gp_01.append(gp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "gp_0_test = []\n",
    "gp_1_test = []\n",
    "gp_01_test= []\n",
    "gp_nan_test = []\n",
    "for col in df_gd_test.group_1.unique():\n",
    "    if col in gp_0:\n",
    "        gp_0_test.append(col)\n",
    "    elif col in gp_1:\n",
    "        gp_1_test.append(col)\n",
    "    elif col in gp_01:\n",
    "        gp_01_test.append(col)\n",
    "    else :\n",
    "        gp_nan_test.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "gp_dict = dict()\n",
    "for gp in gp_01_test:\n",
    "    gp_dict[gp] = []\n",
    "    a = df_gd[df_gd.group_1==gp].loc[:,['days','outcome']].sort_values(by=['days'])\n",
    "    for i in range(len(df_gd[df_gd.group_1==gp])-1):\n",
    "        if a.iloc[i].outcome - a.iloc[i+1].outcome == 1:\n",
    "            gp_dict[gp].append(a.iloc[i].days)\n",
    "        elif a.iloc[i].outcome - a.iloc[i+1].outcome == -1:\n",
    "            gp_dict[gp].append(-a.iloc[i].days)\n",
    "        else:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(gp_0), len(gp_1), len(gp_01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(gp_0_test), len(gp_1_test), len(gp_01_test), len(gp_nan_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gp_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gd_test.loc.__setitem__((df_gd_test.loc[:,'group_1'].isin(gp_0_test), ('outcome')), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_gd_test.loc.__setitem__((df_gd_test.loc[:,'group_1'].isin(gp_1_test), ('outcome')), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gd_test[df_gd_test.loc[:,'group_1'].isin(gp_01_test)].loc[:,'group_1'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_gd_test[df_gd_test.loc[:,'group_1'].isin(gp_01_test)].loc[:,'group_1'].iloc[390]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in idx_list:\n",
    "    df_gd_test[df_gd_test.loc[:,'group_1'].isin(gp_01_test)].loc[:,'group_1'].iloc[390]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_gd_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "gd_test_group1 = df_gd_test.loc[:, 'group_1'].copy()\n",
    "gd_test_outcome = df_gd_test.loc[:, 'outcome'].copy()\n",
    "gd_test_days = df_gd_test.loc[:, 'days'].copy()\n",
    "\n",
    "for i in range(1000):  # range(len(df_gd_test)):\n",
    "    if gd_test_group1.iloc[i] in gp_0:\n",
    "        gd_test_outcome.iloc[i] = 0\n",
    "    elif gd_test_group1.iloc[i] in gp_1:\n",
    "        gd_test_outcome.iloc[i] = 1\n",
    "    elif gd_test_group1.iloc[i] in gp_01:\n",
    "        if len(gp_dict[gd_test_group1.iloc[i]]) == 2:\n",
    "            if gp_dict[gd_test_group1.iloc[i]][0] < 0 :\n",
    "                if abs(gp_dict[gd_test_group1.iloc[i]][0]) > gd_test_days.iloc[i]:\n",
    "                    gd_test_outcome.iloc[i] = 0\n",
    "                elif abs(gp_dict[gd_test_group1.iloc[i]][0]) < gd_test_days.iloc[i] < abs(gp_dict[gd_test_group1.iloc[i]][1]): \n",
    "                    gd_test_outcome.iloc[i] = 1\n",
    "                else :\n",
    "                    gd_test_outcome.iloc[i] = 0\n",
    "            else :\n",
    "                if abs(gp_dict[gd_test_group1.iloc[i]][0]) > gd_test_days.iloc[i]:\n",
    "                    gd_test_outcome.iloc[i] = 1\n",
    "                elif abs(gp_dict[gd_test_group1.iloc[i]][0]) < gd_test_days.iloc[i] < abs(gp_dict[gd_test_group1.iloc[i]][1]): \n",
    "                    gd_test_outcome.iloc[i] = 0\n",
    "                else :\n",
    "                    gd_test_outcome.iloc[i] = 1\n",
    "        else :\n",
    "            if gp_dict[gd_test_group1.iloc[i]][0] < 0:\n",
    "                if abs(gp_dict[gd_test_group1.iloc[i]][0]) > gd_test_days.iloc[i]:\n",
    "                    gd_test_outcome.iloc[i] = 0\n",
    "                else : \n",
    "                    gd_test_outcome.iloc[i] = 1\n",
    "            else :\n",
    "                if abs(gp_dict[gd_test_group1.iloc[i]][0]) > gd_test_days.iloc[i]:\n",
    "                    gd_test_outcome.iloc[i] = 1\n",
    "                else : \n",
    "                    gd_test_outcome.iloc[i] = 0\n",
    "    else:\n",
    "        gd_test_outcome.iloc[i] = 3\n",
    "    if len(df_gd_test) % 5 == 0:\n",
    "        print(10000/len(df_gd_test)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(25,3))\n",
    "plt.scatter(df_gd[df_gd.loc[:,'group_1']==gp_01[0]]['days'], df_gd[df_gd.loc[:,'group_1']==gp_01[0]].outcome, alpha = 0.25) \n",
    "plt.ylim(-0.1,1.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(25,3))\n",
    "plt.scatter(df_gd[df_gd.loc[:,'group_1']==gp_01[1]]['days'], df_gd[df_gd.loc[:,'group_1']==gp_01[1]].outcome, alpha = 0.25) \n",
    "plt.ylim(-0.1,1.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(25,3))\n",
    "plt.scatter(df_gd[df_gd.loc[:,'group_1']==gp_01[2]]['days'], df_gd[df_gd.loc[:,'group_1']==gp_01[2]].outcome, alpha = 0.25) \n",
    "plt.ylim(-0.1,1.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for d in ['date_x', 'date_y']:\n",
    "    print('Start of ' + d + ': ' + str(df_merge[d].min().date()))\n",
    "    print('  End of ' + d + ': ' + str(df_merge[d].max().date()))\n",
    "    print('Range of ' + d + ': ' + str(df_merge[d].max() - df_merge[d].min()) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_merge.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_merge[['date_x', 'date_y']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(df_merge.people_id, dtype='object').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_merge.people_id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ppl 별 구매 경향\n",
    "plt.figure(figsize=(20,30))\n",
    "for i, ppl in enumerate(df_merge.people_id.unique()[:20]):\n",
    "    plt.subplot(10,2,i+1)    \n",
    "    plt.scatter(df_merge[df_merge.people_id == ppl]['Past_days'], \\\n",
    "                df_merge[df_merge.people_id == ppl].outcome, alpha = 0.25) \n",
    "    plt.ylim(-0.1,1.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_merge.people_id.value_counts().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ppl 별 구매 경향 top 5\n",
    "plt.figure(figsize=(20,10))\n",
    "for i, ppl in enumerate([294918, 370270, 105739, 54699, 64887]):\n",
    "    plt.subplot(5,1,i+1)    \n",
    "    plt.scatter(df_merge[df_merge.people_id == ppl]['Past_days'], \\\n",
    "                df_merge[df_merge.people_id == ppl].outcome, alpha = 0.25) \n",
    "    plt.ylim(-0.1,1.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# group 별 구매 경향\n",
    "plt.figure(figsize=(20,30))\n",
    "for i, group in enumerate(df_merge.group_1.unique()[:20]):\n",
    "    plt.subplot(10,2,i+1)    \n",
    "    plt.scatter(df_merge[df_merge.group_1 == group]['Past_days'], \\\n",
    "                df_merge[df_merge.group_1 == group].outcome, alpha = 0.25) \n",
    "    plt.ylim(-0.1,1.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# group 별 구매 경향 top 5\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "for i, group in enumerate([17304, 667, 8386, 9280,450]):\n",
    "    plt.subplot(5,1,i+1)    \n",
    "    plt.scatter(df_merge[df_merge.group_1 == group]['Past_days'], \\\n",
    "                df_merge[df_merge.group_1 == group].outcome, alpha = 0.25) \n",
    "    plt.ylim(-0.1,1.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.factorplot(x=\"week_x\", y=\"outcome\", row=\"activity_category\", data=df_merge,\n",
    "               size=2, aspect=3, kind=\"point\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.factorplot(x=\"activity_category\", y=\"outcome\", row=\"week_x\", data=df_merge,\n",
    "               size=2, aspect=3, kind=\"point\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_sample = df_merge.sample(frac = 0.1, random_state=0).copy()\n",
    "df_sample = add_bool_sum(df_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_sample2 = df_merge.sample(frac = 0.1, random_state=1).copy()\n",
    "df_sample2 = add_bool_sum(df_sample2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_sample.groupby(['activity_id', 'activity_category']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,4))\n",
    "sns.kdeplot(df_sample[df_sample.outcome==0]['Past_days'])\n",
    "sns.kdeplot(df_sample[df_sample.outcome==1]['Past_days'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,4))\n",
    "sns.kdeplot(df_sample[df_sample.outcome==0]['week_x'])\n",
    "sns.kdeplot(df_sample[df_sample.outcome==1]['week_x'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### char_1_x ~ char_9_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,12))\n",
    "for i, feat in enumerate(df_sample.columns[list(df_sample).index('char_1_x'):list(df_sample).index('char_9_x')+1]):\n",
    "    plt.subplot(3,3,i+1)\n",
    "    sns.countplot(feat, hue='outcome', data=df_sample)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### char_2_y ~ char_9_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.countplot('char_2_y', hue='outcome', data=df_sample)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,12))\n",
    "for i, feat in enumerate(df_sample.columns[list(df_sample).index('char_3_y'):list(df_sample).index('char_9_y')+1]):\n",
    "    plt.subplot(3,3,i+1)\n",
    "    sns.countplot(feat, hue='outcome', data=df_sample)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### char_10_y ~ char_37"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,30))\n",
    "for i, feat in enumerate(df_sample.columns[list(df_sample).index('char_10_y'):list(df_sample).index('char_37')+1]):\n",
    "    plt.subplot(7,4,i+1)\n",
    "    sns.countplot(feat, hue='outcome', data=df_sample)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,5))\n",
    "sns.countplot('bool_sum', hue='outcome', data=df_sample)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### char_38"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "facet = sns.FacetGrid(df_sample, hue='outcome', aspect=4)\n",
    "facet.map(sns.kdeplot, 'char_38', shade=True)\n",
    "facet.set(xlim=(0, df_sample['char_38'].max()))\n",
    "facet.add_legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.boxplot(x=\"outcome\", y=\"char_38\", data=df_sample)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del df_sample, df_sample2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model1 = sm.OLS.from_formula(\"outcome ~ char_10_y + char_11 + char_12 + char_13 + char_14 + char_15 + char_16 + char_17 + char_18 + \\\n",
    "                            char_19 + char_20 + char_21 + char_22 + char_23 + char_24 + char_25 + char_26 + char_27 + char_28 + \\\n",
    "                            char_29 + char_30 + char_31 + char_32 + char_33 + char_34 + char_35 + char_36 + char_37\", data=df_merge)\n",
    "model2 = sm.OLS.from_formula(\"outcome ~ bool_sum\", data=df_merge)\n",
    "model3 = sm.OLS.from_formula(\"outcome ~ char_10_y + char_11 + char_12 + char_13 + char_14 + char_15 + char_16 + char_17 + char_18 + \\\n",
    "                            char_19 + char_20 + char_21 + char_22 + char_23 + char_24 + char_25 + char_26 + char_27 + char_28 + char_29 + \\\n",
    "                            char_30 + char_31 + char_32 + char_33 + char_34 + char_35 + char_36 + char_37 + bool_sum\", data=df_merge)\n",
    "result1 = model1.fit()\n",
    "result2 = model2.fit()\n",
    "result3 = model3.fit()\n",
    "\n",
    "sm.stats.anova_lm(result1, result2, result3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sm.stats.anova_lm(result1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sm.stats.anova_lm(result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sm.stats.anova_lm(result3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_merge.fillna(0, inplace=True)\n",
    "df_merge_test.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = list(df_merge)\n",
    "a.remove('date_x')\n",
    "a.remove('date_y')\n",
    "a.remove('bool_sum')\n",
    "a.remove('people_id')\n",
    "a.remove('activity_id')\n",
    "a.remove('week_x')\n",
    "a.remove('week_y')\n",
    "a.remove('days')\n",
    "a.remove('group_1')\n",
    "a.remove('outcome')\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_merge2 = one_hot_encoder(df_merge, ['activity_id', 'activity_category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_merge_test2 = one_hot_encoder(df_merge_test, ['activity_id', 'activity_category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a2 = list(df_merge2)\n",
    "a2.remove('date_x')\n",
    "a2.remove('date_y')\n",
    "a2.remove('bool_sum')\n",
    "a2.remove('people_id')\n",
    "a2.remove('week_x')\n",
    "a2.remove('week_y')\n",
    "a2.remove('days')\n",
    "a2.remove('group_1')\n",
    "a2.remove('outcome')\n",
    "print(a2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 로지스틱 회귀분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logit_mod = sm.Logit.from_formula(\"outcome ~ Past_days + char_38 + bool_sum\", data=df_merge)\n",
    "logit_res = logit_mod.fit(disp=0)\n",
    "print(logit_res.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 나이브 베이즈"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 가우시안 정규 분포 나이브 베이즈 모형"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "clf_norm = GaussianNB().fit(df_merge[a], df_merge.outcome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "cross_val_score(clf_norm, df_merge[a], df_merge.outcome, scoring=\"roc_auc\", cv=10).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 의사 결정 나무"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tree = DecisionTreeClassifier(criterion='entropy', max_depth=10).fit(df_merge[a], df_merge.outcome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cross_val_score(tree, df_merge[a], df_merge.outcome, scoring=\"roc_auc\", cv=10).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "draw_decision_tree(tree, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df_submission = pd.DataFrame({'activity_id' : df_test_act_id, 'outcome' : tree2.predict(df_merge_test[a])}).set_index('activity_id')\n",
    "# df_submission.to_csv(\"df_submission_tree.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 랜덤 포레스트"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=30, max_depth=10).fit(df_merge[a], df_merge.outcome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cross_val_score(rfc, df_merge[a], df_merge.outcome, scoring=\"roc_auc\", cv=10).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "importance = rfc.feature_importances_\n",
    "importance = pd.DataFrame(importance, index=df_merge.loc[:,a].columns, \n",
    "                          columns=[\"Importance\"])\n",
    "\n",
    "importance[\"Std\"] = np.std([tree.feature_importances_ for tree in rfc.estimators_], axis=0)\n",
    "\n",
    "x = range(importance.shape[0])\n",
    "y = importance.iloc[:, 0]\n",
    "yerr = importance.iloc[:, 1]\n",
    "\n",
    "plt.bar(x, y)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "importance.sort_values(by='Importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # rfc = RandomForestClassifier(n_estimators=30).fit(df_merge[a], df_merge.outcome) 0.88\n",
    "# df_submission = pd.DataFrame({'activity_id' : df_test_act_id, 'outcome' : rfc.predict(df_merge_test[a])}).set_index('activity_id')\n",
    "# df_submission.to_csv(\"df_submission_rfc.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "efc = ExtraTreesClassifier(n_estimators=30, max_depth=10).fit(df_merge[a], df_merge.outcome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "cross_val_score(efc, df_merge[a], df_merge.outcome, scoring=\"roc_auc\", cv=10).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df_submission = pd.DataFrame({'activity_id' : df_test_act_id, 'outcome' : efc.predict(df_merge_test[a])}).set_index('activity_id')\n",
    "# df_submission.to_csv(\"df_submission_efc.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "xgb = xgboost.XGBClassifier(n_estimators=30, max_depth=10).fit(df_merge2[a2], df_merge2.outcome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "cross_val_score(xgb, df_merge[a2], df_merge.outcome, scoring=\"roc_auc\", cv=10).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df_submission = pd.DataFrame({'activity_id' : df_test_act_id, 'outcome' : xgb.predict(df_merge_test2[a2])}).set_index('activity_id')\n",
    "# df_submission.to_csv(\"df_submission_xgb2.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 퍼셉트론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 서포트 벡터 머신"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_submission = pd.DataFrame({'activity_id' : df_test_act_id, \n",
    "                              'outcome0' : clf_norm.predict(df_merge_test[a]),\n",
    "                              'outcome1' : tree.predict(df_merge_test[a]),\n",
    "                              'outcome2' : rfc.predict(df_merge_test[a]),\n",
    "                              'outcome3' : efc.predict(df_merge_test[a]),\n",
    "                              'outcome4' : xgb.predict(df_merge_test2[a2]),\n",
    "                             })\n",
    "# df_submission.to_csv(\"df_submission_xgb2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_submission['outcome5'] = df_submission.outcome0 + df_submission.outcome1 + df_submission.outcome2 + df_submission.outcome3 + df_submission.outcome4             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_submission['outcome'] = df_submission['outcome5']//3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_submission = df_submission.loc[:,['activity_id', 'outcome']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_submission.set_index('activity_id',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df_submission.to_csv(\"df_submission_vote.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# H2O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h2o.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coltype_dict = dict()\n",
    "ignore_list = ['people_id', 'activity_id', 'group_1', 'char_10_x']\n",
    "numeric_list = ['char_38', 'bool_sum', 'days', 'Past_days']\n",
    "date_list = ['date_x', 'date_y']\n",
    "for col in list(df_merge):\n",
    "    type_ = 'string'\n",
    "    if col in ignore_list:\n",
    "        type_ = 'string'\n",
    "    elif col in numeric_list:\n",
    "        type_ = 'numeric'\n",
    "    elif col in date_list:\n",
    "        type_ = 'time'\n",
    "    else:\n",
    "        type_ = 'enum'\n",
    "    coltype_dict[col] = type_\n",
    "print(coltype_dict)\n",
    "print()\n",
    "\n",
    "na_dict = dict()\n",
    "na_list = ['char_{}_x'.format(x) for x in range(1, 10)]\n",
    "for item in na_list:\n",
    "    na_dict[item] = ['0']\n",
    "print(na_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "hf_merge1 = h2o.H2OFrame(df_merge , column_types=coltype_dict, na_strings=na_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# del ignore_list, numeric_list, date_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "rf_v1 = H2ORandomForestEstimator(\n",
    "    model_id=\"rf_covType_v1\",\n",
    "    ntrees=100,\n",
    "    stopping_rounds=2,\n",
    "    score_each_iteration=True,\n",
    "    seed=1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "rf_v1.train(a, 'outcome', training_frame=hf_merge1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "roc = rf_v1.roc()\n",
    "\n",
    "plt.plot(roc[0], roc[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "hf_merge1_test = h2o.H2OFrame(df_merge_test , column_types=coltype_dict, na_strings=na_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf_v1_predict = rf_v1.predict(hf_merge1_test[a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# rf_v1.varimp(use_pandas = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf_v1_predict_df = rf_v1_predict[['predict', 'p0', 'p1']].as_data_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df_submission_h2o = pd.DataFrame({'activity_id' : df_test_act_id, \n",
    "#                               'outcome' : rf_v1_predict_df['p1']\n",
    "#                              }).set_index('activity_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df_submission_h2o.to_csv(\"df_submission_h2o_p.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
